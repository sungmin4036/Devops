### K8s 역사

![image](https://user-images.githubusercontent.com/62640332/156980440-94370a9b-f111-4b42-9049-44e1974fa2d3.png)


#### 전통적인 배포 시대

: 초기 조직은 애플리케이션을 물리 서버에서 실행했었다. 한 물리 서버에서 여러 애플리케이션의 리소스 한계를 정의할 방법이 없었기에, 리소스 할당의 문제가 발생했다. 예를 들어 물리 서버 하나에서 여러 애플리케이션을 실행하면, 리소스 전부를 차지하는 애플리케이션 인스턴스가 있을 수 있고, 결과적으로는 다른 애플리케이션의 성능이 저하될 수 있었다. 이에 대한 해결책은 서로 다른 여러 물리 서버에서 각 애플리케이션을 실행하는 것이 있다. 그러나 이는 리소스가 충분히 활용되지 않는다는 점에서 확장 가능하지 않았으므로, 물리 서버를 많이 유지하기 위해서 조직에게 많은 비용이 들었다.

#### 가상화된 배포 시대

: 그 해결책으로 가상화가 도입되었다. 이는 단일 물리 서버의 CPU에서 여러 가상 시스템 (VM)을 실행할 수 있게 한다. 가상화를 사용하면 VM간에 애플리케이션을 격리하고 애플리케이션의 정보를 다른 애플리케이션에서 자유롭게 액세스 할 수 없으므로, 일정 수준의 보안성을 제공할 수 있다.

가상화를 사용하면 물리 서버에서 리소스를 보다 효율적으로 활용할 수 있으며, 쉽게 애플리케이션을 추가하거나 업데이트할 수 있고 하드웨어 비용을 절감할 수 있어 더 나은 확장성을 제공한다. 가상화를 통해 일련의 물리 리소스를 폐기 가능한(disposable) 가상 머신으로 구성된 클러스터로 만들 수 있다.

각 VM은 가상화된 하드웨어 상에서 자체 운영체제를 포함한 모든 구성 요소를 실행하는 하나의 완전한 머신이다.

#### 컨테이너 개발 시대

: 컨테이너는 VM과 유사하지만 격리 속성을 완화하여 애플리케이션 간에 운영체제(OS)를 공유한다. 그러므로 컨테이너는 가볍다고 여겨진다. VM과 마찬가지로 컨테이너에는 자체 파일 시스템, CPU 점유율, 메모리, 프로세스 공간 등이 있다. 기본 인프라와의 종속성을 끊었기 때문에, 클라우드나 OS 배포본에 모두 이식할 수 있다.

컨테이너는 다음과 같은 추가적인 혜택을 제공하기 때문에 인기가 있다.

- 기민한 애플리케이션 생성과 배포: VM 이미지를 사용하는 것에 비해 컨테이너 이미지 생성이 보다 쉽고 효율적임.
- 지속적인 개발, 통합 및 배포: 안정적이고 주기적으로 컨테이너 이미지를 빌드해서 배포할 수 있고 (이미지의 불변성 덕에) 빠르고 효율적으로 롤백할 수 있다.
- 개발과 운영의 관심사 분리: 배포 시점이 아닌 빌드/릴리스 시점에 애플리케이션 컨테이너 이미지를 만들기 때문에, 애플리케이션이 인프라스트럭처에서 분리된다.
- 가시성(observability): OS 수준의 정보와 메트릭에 머무르지 않고, 애플리케이션의 헬스와 그 밖의 시그널을 볼 수 있다.
- 개발, 테스팅 및 운영 환경에 걸친 일관성: 랩탑에서도 클라우드에서와 동일하게 구동된다.
- 클라우드 및 OS 배포판 간 이식성: Ubuntu, RHEL, CoreOS, 온-프레미스, 주요 퍼블릭 클라우드와 어디에서든 구동된다.
- 애플리케이션 중심 관리: 가상 하드웨어 상에서 OS를 실행하는 수준에서 논리적인 리소스를 사용하는 OS 상에서 애플리케이션을 실행하는 수준으로 추상화 수준이 높아진다.
- 느슨하게 커플되고, 분산되고, 유연하며, 자유로운 마이크로서비스: 애플리케이션은 단일 목적의 머신에서 모놀리식 스택으로 구동되지 않고 보다 작고 독립적인 단위로 쪼개져서 동적으로 배포되고 관리될 수 있다.
- 리소스 격리: 애플리케이션 성능을 예측할 수 있다.
- 자원 사용량: 리소스 사용량: 고효율 고집적.


### 쿠버네티스가 왜 필요하고 무엇을 할 수 있나

프로덕션 환경에서는 애플리케이션을 실행하는 컨테이너를 관리하고 가동 중지 시간이 없는지 확인해야 한다.

예를 들어 컨테이너가 다운되면 다른 컨테이너를 다시 시작해야 한다. 이 문제를 시스템에 의해 처리한다면 더 쉽지 않을까?

그것이 쿠버네티스가 필요한 이유이다! 쿠버네티스는 분산 시스템을 탄력적으로 실행하기 위한 프레임 워크를 제공한다.

애플리케이션의 확장과 장애 조치를 처리하고, 배포 패턴 등을 제공한다.


- 서비스 디스커버리와 로드 밸런싱 쿠버네티스는 DNS 이름을 사용하거나 자체 IP 주소를 사용하여 컨테이너를 노출할 수 있다. 컨테이너에 대한 트래픽이 많으면, 쿠버네티스는 네트워크 트래픽을 로드밸런싱하고 배포하여 배포가 안정적으로 이루어질 수 있다.

- 스토리지 오케스트레이션 쿠버네티스를 사용하면 로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탑재 할 수 있다.

- 자동화된 롤아웃과 롤백 쿠버네티스를 사용하여 배포된 컨테이너의 원하는 상태를 서술할 수 있으며 현재 상태를 원하는 상태로 설정한 속도에 따라 변경할 수 있다.

   예를 들어 쿠버네티스를 자동화해서 배포용 새 컨테이너를 만들고, 기존  컨테이너를 제거하고, 모든 리소스를 새 컨테이너에 적용할 수 있다.

- 자동화된 빈 패킹(bin packing) 컨테이너화된 작업을 실행하는데 사용할 수 있는 쿠버네티스 클러스터 노드를 제공한다. 각 컨테이너가 필요로 하는 CPU와 메모리(RAM)를 쿠버네티스에게 지시한다. 
   쿠버네티스는 컨테이너를 노드에 맞추어서 리소스를 가장 잘 사용할 수 있도록 해준다.

- 자동화된 복구(self-healing) 쿠버네티스는 실패한 컨테이너를 다시 시작하고, 컨테이너를 교체하며, '사용자 정의 상태 검사'에 응답하지 않는 컨테이너를 죽이고, 서비스 준비가 끝날 때까지 그러한 과정을 클라이언트에 보여주지 않는다.

- 시크릿과 구성 관리 쿠버네티스를 사용하면 암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리 할 수 있다. 컨테이너 이미지를 재구성하지 않고 스택 구성에 시크릿을 노출하지 않고도 시크릿 및 애플리케이션 구성을 배포 및 업데이트 할 수 있다.








![image](https://user-images.githubusercontent.com/62640332/155851594-0713417c-a3e3-4e98-8652-6d2cf7496241.png)



실제 애플리케이션은 여러 컨테이너에 걸쳐 있고 이러한 컨테이너는 여러 서버에 배포되어 있습니다.

이렇게 여러 대의 서버나 하드웨어를 모아서 한 대처럼 보이게 하는 기술을 클러스터링(clustering)이라고 합니다.

이를 통해서 가용성과 확장성을 향상시킬 수 있습니다.

이런 멀티호스트 환경에서 컨테이너를 클러스터링하기 위한 툴을 컨테이너 오케스트레이션 툴이라고 합니다. 

오케스트레이션 툴은 컨테이너들을 클러스터링하기 위해 컨테이너 시작 및 정지와 같은 조작, 호스트 간 네트워크 연결, 스토리지 관리, 컨테이너를 어떤 호스트에서 가동시킬지와 같은 스케줄링 기능을 제공합니다.

- 쿠버네티스(Kubernetes)는 Linux 컨테이너 작업을 자동화하는 오픈소스 플랫폼, 이 플랫폼에서는 컨테이너화된 애플리케이션을 배포하고 확장하는 데 수동 프로세스가 필요하지 않습니다. 쿠버네티스를 통해 물리 서버 또는 가상 머신의 클러스터에서 컨테이너를 예약하고 실행할 수 있는 플랫폼을 제공하며, 쿠버네티스 아키텍처는 상호 연계된 구성 요소로 클러스터를 나누어 클러스터를 정의된 상태로 유지


실제 프로덕션 애플리케이션은 여러 컨테이너에 걸쳐 있으며 이러한 컨테이너는 여러 서버 호스트에 배포되어야 합니다. 

컨테이너를 위한 보안은 멀티레이어 구조이며 복잡할 수 있습니다.  바로 여기에 쿠버네티스가 사용됩니다. 

쿠버네티스는 이러한 워크로드를 위해 규모에 맞는 컨테이너를 배포하는 데 필요한 오케스트레이션 및 관리 기능을 제공합니다.

 쿠버네티스 오케스트레이션을 사용하면 여러 컨테이너에 걸쳐 애플리케이션 서비스를 구축하고 클러스터 전체에서 컨테이너의 일정을 계획하고 이러한 컨테이너를 확장하여 컨테이너의 상태를 지속적으로 관리할 수 있습니다. 
 
 쿠버네티스를 활용하면 IT 보안을 한층 강화할 수 있습니다.

 ![image](https://user-images.githubusercontent.com/62640332/148711179-d1b399ee-7275-4ecd-9fb8-2e78b19c15c6.png)





Linux 컨테이너를 사용하는 가장 기본적인 방식은 컨테이너를 효율적이고 빠른 가상 머신으로 다루는 것

이를 프로덕션 환경과 여러 애플리케이션으로 확장하고 나면 개별 서비스를 제공하기 위해 같은 위치에 배치된 여러 개의 컨테이너를 함께 사용해야 한다는 것을 분명히 알 수 있습니다.

따라서 환경에서 컨테이너 수가 크게 증가하며 컨테이너가 누적됨에 따라 복잡성도 증가


쿠버네티스는 컨테이너를 "포드(pod)"로 분류하여  컨테이너 급증과 관련된 여러 가지 문제를 해결합니다. 

포드는 그룹화된 컨테이너에 추상화 계층을 추가하므로 사용자가 워크로드를 예약하고 네트워킹 및 저장소와 같은 필수 서비스를 컨테이너에 제공할 수 있습니다.

 쿠버네티스의 또 다른 부분을 사용해 이러한 포드 전체에서 부하를 분산하고 적합한 수의 컨테이너를 실행하여 워크로드를 지원할 수 있습니다.



ㅁ 쿠버네티스 주요 이점은

 1. 특히 클라우드를 위한 애플리케이션 개발을 최적화하는 중인 경우, 쿠버네티스를 통해 물리 또는 가상 머신의 클러스트에서 컨테이너를 예약하고 실행할 수 있는 플랫폼이 확보
 
 -> 더 넓게 보면, 프로덕션 환경에 컨테이너 기반 인프라를 완전히 구현해서 사용할 수 있습니다.

2. 버네티스는 운영 작업 자동화와 관련이 있으므로 다른 애플리케이션 플랫폼 또는 관리 시스템에서 가능한 작업의 상당수를 컨테이너를 사용해 수행할 수 있습니다.


ㅁ 쿠버네티스 수행 가능한 작업

1. 여러 호스트에 걸쳐 컨테이너를 오케스트레이션합니다.

2. 하드웨어를 최대한 활용하여 엔터프라이즈 애플리케이션을 실행하는 데 필요한 리소스를 극대화합니다.

3. 애플리케이션 배포 및 업데이트를 제어하고 자동화합니다.

4. 스토리지를 장착 및 추가해 스테이트풀(stateful) 애플리케이션을 실행합니다.

5. 컨테이너화된 애플리케이션과 해당 리소스를 즉시 확장합니다.

6. 선언적으로(Declaratively) 서비스를 관리함으로써, 배포한 애플리케이션이 항상 배포 목적대로 실행되도록 합니다.

7. 자동 배치, 자동 재시작, 자동 복제, 자동 확장을 사용해 애플리케이션 상태 확인과 셀프 복구를 수행합니다.


ㅁ 쿠버네티스 기술 용어

- 마스터: 쿠버네티스 노드를 제어하는 머신입니다. 여기에서 모든 태스크 할당이 시작됩니다.

- 노드: 할당된 태스크를 요청대로 수행하는 시스템입니다. 쿠버네티스 마스터가 이러한 노드를 제어합니다.

- 포드: 단일 노드에 배포된 하나 이상의 컨테이너 그룹입니다. 포드에 있는 모든 컨테이너는 IP 주소, IPC, 호스트 이름, 기타 리소스를 공유하며 포드는 기본 컨테이너에서 네트워크와 스토리지를 추상화합니다 이렇게 하면 클러스터에서 컨테이너를 더 쉽게 이동할 수 있습니다.

- 복제 컨트롤러:  이 컨트롤러는 클러스터에서 실행되어야 하는 동일한 포드 사본의 개수를 제어합니다.

- 서비스: 포드에서 작업 정의를 분리합니다 쿠버네티스 서비스 프록시는 클러스터에서 다른 위치로 이동한 경우든 교체된 경우든 서비스 요청을 적절한 포드로 자동 수신합니다.

- Kubelet: 이 서비스는 노드에서 실행되며 컨테이너 매니페스트를 읽고, 정의된 컨테이너가 시작되어 실행 중인지 확인합니다

- kubectl: 쿠버네티스의 명령줄 설정 툴입니다.

![image](https://user-images.githubusercontent.com/62640332/148711526-e7513127-ce05-4405-a5dc-494575d7ba87.png)


쿠버네티스는 운영 체제를 기반으로 실행.

 노드에서 실행되는 컨테이너의 포드와 상호작용합니다.

 쿠버네티스 마스터는 관리자(또는 DevOps팀)으로부터 명령을 전달받고 해당 지침을 하위 노드에 이어서 전달합니다.

 이 핸드오프는 여러 서비스와 연계하여 태스크에 가장 적합한 노드를 자동으로 결정합니다 그 후 리소스를 할당하고 해당 노드에 포드를 지정하여 요청된 작업을 수행합니다.



 쿠버네티스 ? 분산형 애플리케이션 및 서비스를 규모에 맞게 실행하도록 설계된 오픈소스 컨테이너 오케스트레이션 플랫폼

쿠버네티스 클러스터는 애플리케이션 컨테이너를 실행하기 위한 일련의 노드 머신입니다.   쿠버네티스를 실행 중이라면 클러스터를 실행하고 있는 것입니다.

최소 수준에서 클러스터는 컨트롤 플레인 및 하나 이상의 컴퓨팅 머신 또는 노드를 포함하고 있습니다. 

컨트롤 플레인은 어느 애플리케이션을 실행하고 애플리케이션이 어느 컨테이너 이미지를 사용할지와 같이 클러스터를 원하는 상태로 유지 관리합니다. 노드는 애플리케이션과 워크로드를 실제로 실행합니다.

클러스터는 쿠버네티스의 핵심 장점입니다. 즉 물리 머신, 가상 머신, 온프레미스, 클라우드에 구애받지 않고 머신 그룹 전체에서 컨테이너를 예약하고 실행할 수 있습니다. 쿠버네티스 컨테이너는 개별 머신에 연결되지 않습니다. 대신에 클러스터 전체에서 추상화됩니다.

원하는 클러스터 상태는 쿠버네티스 API로 정의됩니다. 이러한 정의는 커맨드라인에서(kubectl 사용) 또는 API를 사용해 클러스터와 상호 작용하여 원하는 상태를 설정하거나 수정할 수 있습니다.

쿠버네티스는 원하는 상태에 부합하도록 자동으로 클러스터를 관리합니다

쿠버네티스 패턴을 사용하여 로드에 따라 클러스터 규모를 자동으로 관리할 수도 있습니다. 


<br>

쿠버네티스 클러스터에는 원하는 상태가 있으며, 이 상태는 실행해야 할 애플리케이션이나 워크로드, 사용하는 이미지, 사용할 수 있는 리소스 등과 같은 기타 구성 세부 사항을 정의합니다.

원하는 상태는 매니페스트로 이루어진 구성 파일로 정의됩니다. 매니페스트란 실행할 애플리케이션의 유형과 정상적인 시스템을 실행하기 위해 필요한 복제본의 수를 선언하는 JSON 또는 YAML 파일입니다.



 ㅁ 쿠버네티스 클러스터가 갖춰야 할 특성

1. 보안성: 최신 보안 모범 사례를 따라야 합니다.

2. 사용 편이성: 몇 가지 간단한 명령으로 작동할 수 있어야 합니다. 

3. 확장 가능성: 하나의 제공업체만을 선호해서는 안 되고 구성 파일을 통해 사용자 정의할 수 있어야 합니다.


<br>

작동 중인 쿠버네티스 배포를 클러스터라고 합니다. 쿠버네티스 클러스터는 컨트롤 플레인과 컴퓨팅 머신(또는 노드)의 2개 부분으로 시각화할 수 있습니다.

각 노드는 자체 Linux® 환경이며 물리 또는 가상 머신일 수 있습니다. 각 노드는 컨테이너로 이루어진 포드(Pod)를 실행합니다.

이 다이어그램은 쿠버네티스 클러스터 구성 요소의 상호 관계를 보여줍니다.

![image](https://user-images.githubusercontent.com/62640332/148730197-da5a0989-dcda-4902-811a-af4de84adc7a.png)


<br>

- 컨트롤 플레인

쿠버네티스 클러스터의 신경 중추라 할 수 있는 컨트롤 플레인부터 살펴보겠습니다.

여기에는 클러스터를 제어하는 쿠버네티스 구성 요소와 클러스터의 상태 및 구성에 관한 데이터가 함께 있습니다.
 
이 핵심 쿠버네티스 구성 요소는 컨테이너가 필요한 리소스를 갖고 충분한 횟수로 실행되도록 하는 중요한 작업을 맡습니다. 

컨트롤 플레인은 컴퓨팅 노드와 상시 연결되어 있습니다. 클러스터가 일정한 방식으로 실행되도록 구성했다면 컨트롤 플레인은 해당 방식에 따라 실행됩니다.


1. kube-apiserver    
: 쿠버네티스 클러스터와 상호 작용해야 하나요? API에 요청하세요. 쿠버네티스 API는 쿠버네티스 컨트롤 플레인의 프론트엔드로, 내부 및 외부 요청을 처리합니다. API 서버는 요청이 유효한지 판별하고 유효한 요청을 처리합니다. REST 호출이나 kubectl 커맨드라인 인터페이스 또는 kubeadm과 같은 기타 CLI(command-line interface)를 통해 API에 액세스할 수 있습니다.

2. kube-scheduler   
: 클러스터가 양호한 상태인가? 새 컨테이너가 필요하다면 어디에 적합한가? 쿠버네티스 스케줄러는 이러한 것들을 주로 다룹니다.

스케줄러는 CPU 또는 메모리와 같은 포드의 리소스 요구 사항과 함께 클러스터의 상태를 고려합니다. 그런 다음 포드를 적절한 컴퓨팅 노드에 예약합니다.

3. kube-controller-manager   
: 컨트롤러는 실제로 클러스터를 실행하고 쿠버네티스 controller-manager에는 여러 컨트롤러 기능이 하나로 통합되어 있습니다. 하나의 컨트롤러는 스케줄러를 참고하여 정확한 수의 포드가 실행되게 합니다. 포드에 문제가 생기면 또 다른 컨트롤러가 이를 감지하고 대응합니다. 컨트롤러는 서비스를 포드에 연결하므로 요청이 적절한 엔드포인트로 이동합니다. 또한 계정 및 API 액세스 토큰 생성을 위한 컨트롤러가 있습니다.

4. etcd   
: 설정 데이터와 클러스터의 상태에 관한 정보는 키-값 저장소 데이터베이스인 etcd에 상주합니다. 내결함성을 갖춘 분산형 etcd는 클러스터에 관한 궁극적 정보 소스(Source Of Truth, SOT)가 되도록 설계되었습니다.

<br>

- 버네티스 클러스터 관리가 중요한 이유
: 현재 쿠버네티스 환경은 개별 클러스터 수준에서 관리해야 하기 때문에 엔터프라이즈 전반에서 관리에 드는 비용이 클러스터의 수에 따라 빠르게 증가할 수 있습니다. 

각 클러스터는 보안을 위해 개별적으로 배포, 업그레이드 및 설정해야 합니다. 또한 애플리케이션을 환경 전반에 배포해야 하는 경우 수동으로 또는 쿠버네티스 환경 제어 범위 밖에서 배포를 수행해야 합니다.


개발자는 필요 시 새 클러스터에 쉽게 액세스하고 싶어합니다. 운영 팀과 사이트 신뢰성 엔지니어(SRE)를 위해 애플리케이션을 프로덕션에서 사용할 수 있도록 새 클러스터를 정확히 설정해야 합니다. 또한 운영 팀과 SRE는 여러분의 환경에서 클러스터 상태를 모니터링하고 싶어합니다.

쿠버네티스 클러스터 관리는 관리자와 사이트 신뢰성 엔지니어가 쿠버네티스 클러스터를 실행하는 다양한 환경 전반에서 작업할 때 겪는 공통된 문제를 해결해 줍니다.


<br>

ㅁ 쿠버네티스 노드 개념과 특징

- 노드   
: 쿠버네티스 클러스터에는 최소 1개 이상의 컴퓨팅 노드가 필요하지만 일반적으로 여러 개가 있습니다. 포드는 노드에서 실행하도록 예약되고 오케스트레이션됩니다. 클러스터의 용량을 확장해야 한다면 노드를 더 추가하면 됩니다.

- 포드   
: 포드는 쿠버네티스 오브젝트 모델에서 가장 작고 단순한 유닛으로, 애플리케이션의 단일 인스턴스를 나타냅니다. 각 포드는 컨테이너 실행 방식을 제어하는 옵션과 함께 컨테이너 하나 또는 긴밀히 결합된 일련의 컨테이너로 구성되어 있습니다. 포드를 퍼시스턴트 스토리지에 연결하여 스테이트풀(stateful) 애플리케이션을 실행할 수 있습니다.

- 컨테이너 런타임 엔진     
: 컨테이너 실행을 위해 각 컴퓨팅 노드에는 컨테이너 런타임 엔진이 있습니다. 그중 한 가지 예가 Docker입니다. 하지만 쿠버네티스는 rkt, CRI-O와 같은 다른 Open Container Initiative 호환 런타임도 지원합니다.

- kubelet    
: 각 컴퓨팅 노드에는 컨트롤 플레인과 통신하는 매우 작은 애플리케이션인 kubelet이 있습니다. kublet은 컨테이너가 포드에서 실행되게 합니다. 컨트롤 플레인에서 노드에 작업을 요청하는 경우 kubelet이 이 작업을 실행합니다.

- kube-proxy    
: 각 컴퓨팅 노드에는 쿠버네티스 네트워킹 서비스를 용이하게 하기 위한 네트워크 프록시인 kube-proxy도 있습니다. kube-proxy는 운영 체제의 패킷 필터링 계층에 의존하거나 트래픽 자체를 전달하여 클러스터 내부 또는 외부의 네트워크 통신을 처리합니다.


<br>


- 쿠버네티스 클러스터는 애플리케이션 컨테이너를 실행하기 위한 일련의 노드 머신입니다. 쿠버네티스를 실행 중이라면 클러스터를 실행하고 있는 것입니다.


ㅁ 쿠버네티스 클러스터에 필요한 요소

1. 퍼시스턴트 스토리지   
: 쿠버네티스는 애플리케이션을 실행하는 컨테이너를 관리할 뿐만 아니라 클러스터에 연결된 애플리케이션 데이터도 관리할 수 있습니다. 쿠버네티스를 사용하면 사용자가 기본 스토리지 인프라에 관한 상세 정보를 알지 못해도 스토리지 리소스를 요청할 수 있습니다. 퍼시스턴트 볼륨은 포드가 아닌 클러스터에 따라 다르므로 포드보다 수명이 오래 지속될 수 있습니다.

2. 컨테이너 레지스트리   
: 쿠버네티스가 의존하는 컨테이너 이미지는 컨테이너 레지스트리에 저장됩니다. 이러한 레지스트리를 직접 구성하거나 제 3사가 구성할 수 있습니다.

3. 기본 인프라   
: 쿠버네티스를 원하는 곳에서 실행할 수 있습니다. 즉 베어 메탈 서버, 가상 머신, 퍼블릭 클라우드 제공업체, 프라이빗 클라우드, 하이브리드 클라우드 환경 등에서 실행할 수 있습니다. 쿠버네티스의 주요 이점 중 하나는 다양한 종류의 인프라에서 작동한다는 것입니다.

ㅁ 용어 정리 

1. 컨트롤 플레인: 쿠버네티스 노드를 제어하는 프로세스의 컬렉션입니다. 여기에서 모든 태스크 할당이 시작됩니다.

2. 노드: 컨트롤 플레인에서 할당된 요청 태스크를 수행하는 머신입니다.

3. 포드: 단일 노드에 배포되는 하나 이상의 컨테이너 집합입니다. 포드는 가장 작고 단순한 쿠버네티스 오브젝트입니다.

4. 서비스: 일련의 포드에서 네트워크 서비스로 실행 중인 애플리케이션을 노출하는 방식입니다. 이로 인해 작업 정의가 포드에서 분리됩니다.

5. 볼륨: 포드의 컨테이너에 액세스할 수 있는 데이터가 포함된 디렉토리입니다. 쿠버네티스 볼륨은 이 볼륨을 묶는 포드와 수명이 같습니다. 볼륨은 포드 내에서 실행되는 모든 컨테이너보다 오래 지속되며, 컨테이너를 다시 시작해도 데이터는 보존됩니다.

6. 네임스페이스: 가상 클러스터입니다. 네임스페이스를 통해 쿠버네티스는 동일한 물리 클러스터 내에 있는 여러 클러스터(여러 팀 또는 프로젝트 용도)를 관리할 수 있습니다.

![image](https://user-images.githubusercontent.com/62640332/155844948-73a1a7ff-b4b3-4ec4-8c1a-062669a890c7.png)

쿠버네티스 클러스터는 애플리케이션 컨테이너를 실행하기 위한 일련의 노드 머신입니다. 쿠버네티스를 실행 중이라면 클러스터를 실행하고 있는 것입니다.

최소 수준에서 클러스터는 컨트롤 플레인 및 하나 이상의 컴퓨팅 머신 또는 노드를 포함하고 있습니다. 

컨트롤 플레인은 어느 애플리케이션을 실행하고 애플리케이션이 어느 컨테이너 이미지를 사용할지와 같이 클러스터를 원하는 상태로 유지 관리합니다. 

노드는 애플리케이션과 워크로드를 실제로 실행합니다.

클러스터는 쿠버네티스의 핵심 장점입니다. 

즉 물리 머신, 가상 머신, 온프레미스, 클라우드에 구애받지 않고 머신 그룹 전체에서 컨테이너를 예약하고 실행할 수 있습니다. 

쿠버네티스 컨테이너는 개별 머신에 연결되지 않습니다. 대신에 클러스터 전체에서 추상화됩니다.



쿠버네티스 클러스터는 컨트롤 플레인(마스터 노드)와 워커 노드로 이루어집니다. 


ㅁ 컨트롤 플레인


![image](https://user-images.githubusercontent.com/62640332/155851583-8ac6a3be-629a-4b5c-950f-5ae91fe00867.png)

: 컨트롤 플레인은 쿠버네티스 클러스터의 기능을 제어하는 역할을 합니다. 컨트롤 플레인은 다음과 같은 구성요소로 이루어져 있습니다.

- API Server
- Scheduler
- Controller Manager
- etcd

컨트롤 플레인에서 해당 요소들은 개별적인 프로세스로 동작합니다.

그렇다면 각 구성 요소들은 어떤 방식으로 통신을 하게 될까요? 

정답은 '모든 구성요소는 API 서버로만 통신한다' 입니다. 

예들어 컨트롤러 매니저가 etcd의 데이터를 변경하기 위해서는 API 서버를 통해 요청을 보내야합니다.

쿠버네티스 클러스터의 기능을 제어하기 때문에 컨트롤 플레인이 제 기능을 수행하지 못한다면 쿠버네티스 클러스터도 마찬가지로 본래의 기능을 수행하지 못하게 됩니다.

따라서 컨트롤 플레인이 단일 실패 지점(SPOF)이 되지 않도록 가용성을 확보해야 합니다.

구성 요소가 같은 노드에 존재해야하는 워커 노드와 다르게 컨트롤 플레인의 구성 요소는 여러 서버에 구축될 수 있습니다. 

따라서 여러 노드에 컨트롤 플레인의 구성 요소 인스턴스를 여러개 띄워 가용성을 향상시킬 수 있습니다.

이 때 알아둬야 할 점은 etcd와 API 서버는 여러 인스턴스를 동시에 활성화시켜 병렬로 실행이 가능하지만, 스케줄러와 컨트롤러 매니저는 나머지 인스턴스는 대기 상태로 유지한다는 점입니다.



<br>
<br>
<br>


![image](https://user-images.githubusercontent.com/62640332/155851619-563d8ffd-6280-4cbe-a0c6-72343008f36a.png)


ㅁ etcd

: 쿠버네티스에서 생성된 모든 오브젝트는 상태와 메니페스트를 영속적으로 유지해야 합니다.

이를 위해서 쿠버네티스는 분산 key-value 저장소인 etcd를 사용합니다. 

etcd는 분산된 아키텍처 형태를 가질 수 있으며 이를 통해 고가용성 및 빠른 성능을 제공하게 됩니다.

쿠버네티스는 etcd v2나 v3를 모두 지원하지만 v3가 더 나은 성능을 보여주기 때문에 v3를 사용하는 것을 권장합니다. 

따라서 v3 기준으로 데이터가 어떻게 되는지 살펴보면 etcd는 계층적 key 구조를 통해 쿠버네티스의 데이터를 저장합니다. 

이 때, /registry 아래에 모든 데이터를 저장하게 됩니다.

<br>
<br>
<br>

ㅁ RAFT 합의 알고리즘

: 분산된 etcd 클러스터는 RAFT 합의 알고리즘을 통해 데이터의 일관성을 유지하게 됩니다. 

RAFT 합의 알고리즘을 간단하게 말하자면 클러스터에 Split Brain 현상이 발생하게 되면 과반수가 넘는 노드가 있는 쪽만 유효한 요청을 수행할 수 있다는 알고리즘입니다. 

RAFT 합의 알고리즘과 관련된 내용은 이 글을 살펴보시면 더 자세한 내용을 보실 수 있습니다. 

추가적으로 etcd 인스턴스 수를 일반적으로 홀수로 배포하게 되는데 이는 짝수인 경우 과반이 존재하지 않을 가능성이 높아지기 때문입니다.


<br>
<br>
<br>

ㅁ API Server

:API Server는 클러스터의 모든 구성요소가 다른 구성요소와 통신하기 위해 필요한 중요 구성요소입니다. 

API Server는 클러스터와 관련된 다양한 REST API를 제공합니다.

클라이언트가 API 서버에 리소스 생성 및 조회의 요청을 보내게 되면 다음과 같은 과정을 거치게 됩니다.

- 요청을 보낸 클라이언트가 인증된 클라이언트인지 확인
- 인증된 사용자가 현재 보낸 요청을 수행할 수 있는 권한이 있는지 확인
- (리소스 생성 및 수정, 삭제) 리소스를 기존에 정의된 플러그인을 통해 수정
- 리소스의 유효성을 확인한 후 etcd에 저장
- 리소스의 변경 사항을 리소스를 감시하고 있는 모든 클라이언트에게 통보


<br>
<br>
<br>

ㅁ Controller Manager

: Scheduler를 통해 Pod이 스케줄링 되었다면 다음으로 해야하는 작업은 해당 리소스를 원하는 상태로 만드는 작업입니다. 쿠베네티스에서 이러한 작업을 수행하는 컴포넌트를 Controller라고 합니다. 컨트롤러 매니저는 다양한 컨트롤러들을 실행하는 역할을 담당합니다.


<br>
<br>
<br>


ㅁ Controller

: Controller는 API 서버를 통해 리소스의 변경을 감시하고 변경하는 작업을 담당합니다. 클라이언트가 선언한 Spec으로 조정하며 새롬게 변경된 상태를 Status에 저장합니다. 쿠버네티스에는 기본적으로 제공되는 다양한 Controller가 존재합니다. (ex. Deployment, ReplicaSet, StatefulSet 등)

<br>
<br>
<br>

ㅁ Worker Node

: 워커 노드는 실제 어플리케이션이 실행되는 노드로 kubelet과 kube-proxy라는 구성요소를 가지고 있습니다.

<br>
<br>
<br>

ㅁ Kubelet

: Scheduler에 의해 Pod이 스케줄링되면 API 서버는 Kubelet에게 Pod을 생성하라는 요청을 보냅니다. 이 요청을 받은 Kubelet은 지정된 컨테이너 런타임과 이미지를 사용해 컨테이너를 생성합니다. 또한, 실행 중인 컨테이너를 모니터링하며 관련된 정보를 API 서버에게 보내게 됩니다. 추가로 Liveness Probe가 설정되어 있는 경우, 컨테이너를 재시작하는 역할도 kubulet에서 담당합니다.

<br>
<br>
<br>

ㅁ Kube-Proxy

: Kube-Proxy는 서비스의 IP 및 포트로 들어온 접속을 서비스의 엔드포인트에 해당하는 Pod에 연결하는 역할을 담당합니다. Proxy라는 이름이 붙은 이유는 초기 쿠버네티스 버전에서 kube-proxy는 userspace에서 동작하던 프록시였기 때문입니다. 하지만 현재는 성능이 더 우수한 iptables 프록시 모드로 수행됩니다.



---

#### 쿠버네티스 포드(Kubernetes pod)란?

쿠버네티스 포드는 Linux® 컨테이너를 하나 이상 모아 놓은 것으로, `쿠버네티스 애플리케이션의 최소 단위`입니다. 

강하게 결합된 여러 개의 컨테이너로 구성된 포드도 있고(고급 활용 사례), 단일 컨테이너로만 이루어진 포드도 있습니다(더 일반적인 활용 사례). 

컨테이너를 쿠버네티스 포드로 그룹화하는 이유는 아래의 설명과 같이 리소스를 더 지능적으로 공유하기 위해서입니다.

쿠버네티스 시스템에서는 같은 포드에 속한 컨테이너끼리 동일한 컴퓨팅 리소스를 공유합니다. 

이러한 컴퓨팅 리소스를 쿠버네티스에 풀링하여 클러스터를 만들고, 이를 바탕으로 더 강력하고 지능적으로 분산된 애플리케이션 실행 시스템을 제공할 수 있습니다. 

컨테이너, 포드, 노드, 클러스터 등 쿠버네티스의 구성 요소를 처음에는 이해하기가 쉽지 않을 수도 있습니다. 

쿠버네티스 포드의 장점을 이해하는 데 가장 중요한 요소가 아래에 정리되어 있습니다.

```
ㅁ 하드웨어 유닛

- 노드: 쿠버네티스에서 최소 단위의 컴퓨팅 하드웨어이며, 하나의 개별 머신으로 생각하면 됩니다.

- 클러스터: 지능적인 리소스 공유와 균형 배분을 위해 여러 노드를 묶은 그룹입니다.
```

```
ㅁ 소프트웨어 유닛

- Linux 컨테이너: 하나 이상의 프로세스 모음이며, 실행에 필요한 파일도 모두 들어 있어 머신 간 이식이 가능합니다.

- 쿠버네티스 포드: 하나 이상의 Linux 컨테이너 모음이며, 클러스터 관리를 통한 리소스 공유의 장점을 극대화하기 위해 패키지로 묶여 있습니다.
```

기본적으로 쿠버네티스에서는 개별 하드웨어를 노드라고 부릅니다.

이 노드가 여러 개 모여 클러스터를 이루며, 이로써 필요에 따라 컴퓨팅 성능을 분산시킬 수 있습니다. 

이 클러스터에서 실행되는 것이 포드입니다. 강력하게 결합된 포드 속 컨테이너는 같은 클러스터에서 함께 실행됩니다.

- 쿠버네티스에서 포드를 사용하는 이유

포드와 클러스터의 관계 때문에 쿠버네티스는 직접 컨테이너를 실행하지 않습니다. 

그 대신 포드를 실행하면서 포드 속의 각 컨테이너가 동일한 리소스 및 로컬 네트워크를 공유하게 합니다. 

이런 식으로 컨테이너를 그룹화하면 실제로는 어느 정도 분리된 상태더라도 마치 동일한 물리 하드웨어를 공유하는 것처럼 컨테이너끼리 서로 통신할 수 있게 됩니다.

이렇게 컨테이너를 포드로 구성하는 것이 바로 쿠버네티스의 유명한 기능, 바로 복제의 토대가 됩니다. 

컨테이너를 모아 포드를 만들면 쿠버네티스는 복제 컨트롤러를 사용하여 필요에 따라 애플리케이션을 수평으로 스케일할 수 있습니다. 

다시 말해, 어떤 포드 하나가 과부하 상태가 되면 쿠버네티스는 자동으로 이를 복제한 다음 클러스터에 배포할 수 있습니다. 

쿠버네티스 포드는 과부하 상태에서의 정상 작동을 지원할 뿐만 아니라 지속적으로 복제되면서 시스템의 내장애성을 제공합니다.