
컨테이너 인프라 환경이란 리눅스 운영 체제의 커널 하나에서 여러 개의 컨테이너가 격리된 상태로 실행되는 인프라 환경을 말합니다.

여기서 컨테이너는 하나 이상의 목적을 위해 독립적으로 작동하는 프로세스입니다.

개인 환경에서는 1명의 관리자(사용자)가 다양한 응용프로그램을 사용하므로 각각의 프로그램을 컨테이너로 구현할 필요가 거의 없습니다. 

하지만 기업 환경에서는 다수의 관리자가 수백 또는 수천 대의 서버를 함께 관리하기 때문에 일관성을 유지하는 것이 매우 중요합니다.

이런 경우 컨테이너 인프라 환경을 구성하면 눈송이 서버(여러 사람이 만져서 설정의 일관성이 떨어진 서버)를 방지하는 데 효과적입니다.

가상화 환경에서는 각각의 가상 머신이 모두 독립적인 운영 체제 커널을 가지고 있어야 하기 때문에 그만큼 자원을 더 소모해야 하고 성능이 떨어질 수밖에 없습니다. 

하지만 컨테이너 인프라 환경은 운영 체제 커널 하나에 컨테이너 여러 개가 격리된 형태로 실행되기 때문에 자원을 효율적으로 사용할 수 있고 거치는 단계가 적어서 속도도 훨씬 빠릅니다.

![image](https://user-images.githubusercontent.com/62640332/167587623-bb332b02-f6a2-45d1-8a2c-7d2e9c3aa874.png)

### ㅁ 컨테이너 인프라 환경이 주목 받지 못했던 이유

컨테이너 인프라 환경이 처음부터 주목받았던 것은 아닙니다. 

이미 가상화 환경에서 상용 솔루션(VMware)을 이용해 안정적으로 시스템을 운용하고 있었고, 기술 성숙도가 높아 문제없이 관리되고 있었습니다. 

그러다 시간이 지나 커널을 공유해 더 많은 애플리케이션을 올릴 수 있는 컨테이너가 도입되기 시작하면서 늘어난 컨테이너를 관리해야 했습니다. 

하지만 기존의 컨테이너 관리 솔루션(Docker Swarm, Mesos, Nomad 등)들은 현업의 요구 사항을 충족시키기에는 부족한 점이 있었습니다.

그래서 컨테이너 인프라 환경이 주는 장점이 많이 있음에도 컨테이너 관리 문제 때문에 보편화되기가 어려웠습니다.

그 이후 구글이 쿠버네티스를 오픈소스로 공개하여 컨테이너 관리가 용이해짐.


<br>
<br>

쿠버네티스를 컨테이너 관리 도구라고 설명했지만, 실제로 쿠버네티스는 컨테이너 오케스트레이션을 위한 솔루션입니다. 

오케스트레이션(Orchestration)이란 복잡한 단계를 관리하고 요소들의 유기적인 관계를 미리 정의해 손쉽게 사용하도록 서비스를 제공하는 것을 의미합니다. 

다수의 컨테이너를 유기적으로 연결, 실행, 종료할 뿐만 아니라 상태를 추적하고 보존하는 등 컨테이너를 안정적으로 사용할 수 있게 만들어주는 것이 컨테이너 오케스트레이션입니다

### ㅁ 대표적인 컨테이너 오케스트레이션

![image](https://user-images.githubusercontent.com/62640332/167589921-015c8a2b-9527-469a-b17c-709e8a5ce09c.png)


• 도커 스웜(Docker Swarm): 간단하게 설치할 수 있고 사용하기도 용이합니다. 

그러나 그만큼 기능이 다양하지 않아 대규모 환경에 적용하려면 사용자 환경을 변경해야 할 수 있습니다. 

따라서 소규모 환경에서는 유용하지만 대규모 환경에서는 잘 사용하지 않는 편입니다.

<br>
<br>

• 메소스(Mesos): 아파치(Apache)의 오픈 소스 프로젝트로 역사와 전통이 있는 클러스터 도구이며 트위터, 에어비앤비, 애플, 우버 등 다양한 곳에서 이미 검증된 솔루션입니다. 

메소스는 2016년 DC/OS(Data Center OS, 대규모 서버 환경에서 자원을 유연하게 공유하며 하나의 자원처럼 관리하는 도구)의 지원으로 매우 간결해졌습니다. 

하지만 기능을 충분히 활용하려면 분산 관리 시스템과 연동해야 합니다. 따라서 여러 가지 솔루션을 유기적으로 구성해야 하는 부담이 있습니다.

<br>
<br>

• 노매드(Nomad): 베이그런트를 만든 해시코프(HashiCorp)사의 컨테이너 오케스트레이션으로, 베이그런트처럼 간단한 구성으로 컨테이너 오케스트레이션 환경을 제공합니다. 

하지만 도커 스웜과 마찬가지로 기능이 부족하므로 복잡하게 여러 기능을 사용하는 환경이 아닌 가볍고 간단한 기능만 필요한 환경에서 사용하기를 권장합니다. 

해시코프의 Consul(서비스 검색, 구성 및 분할 기능 제공)과 Vault(암호화 저장소)와의 연동이 원할하므로 이런 도구에 대한 사용 성숙도가 높은 조직이라면 노매드 도입을 고려해볼 수 있습니다.

<br>
<br>


• 쿠버네티스: 다른 오케스트레이션 솔루션보다는 시작하는 데 어려움이 있지만, 쉽게 사용할 수 있도록 도와주는 도구들이 있어서 설치가 쉬워지는 추세입니다. 

또한 다양한 형태의 쿠버네티스가 지속적으로 계속 발전되고 있어서 컨테이너 오케스트레이션을 넘어 IT 인프라 자체를 컨테이너화하고, 컨테이너화된 인프라 제품군을 쿠버네티스 위에서 동작할 수 있게 만듭니다. 

즉 거의 모든 벤더와 오픈 소스 진영 모두에서 쿠버네티스를 지원하고 그에 맞게 통합 개발하고 있습니다. 

그러므로 컨테이너 오케이스트레이션을 학습하거나 도입하려고 한다면 쿠버네티스를 우선적으로 고려해야 합니다.

![image](https://user-images.githubusercontent.com/62640332/167590383-25eb6435-ace8-4906-ba6a-81b7dcaa280c.png)

<br>
<br>


### ㅁ 쿠버네티스 구성하는 방법

1. 퍼블릭 클라우드 업체에서 제공하는 관리형 쿠버네티스인 EKS(Amazon Elastic Kubernetes Service), AKS(Azure Kubernetes Services), GKE(Google Kubernetes Engine) 등을 사용합니다. 

구성이 이미 다 갖춰져 있고 마스터 노드를 클라우드 업체에서 관리하기 때문에 학습용으로는 적합하지 않습니다.
 
<br>

2. 수세의 Rancher, 레드햇의 OpenShift와 같은 플랫폼에서 제공하는 설치형 쿠버네티스를 사용합니다. 

하지만 유료라 쉽게 접근하기 어렵습니다.

<br>

3. 사용하는 시스템에 쿠버네티스 클러스터를 자동으로 구성해주는 솔루션을 사용합니다. 주요 솔루션으로는 kubeadm, kops(Kubernetes Operations), KRIB(Kubernetes Rebar Integrated Bootstrap), kubespray가 있습니다. 

4가지의 주요 솔루션 중에 kubeadm이 가장 널리 알려져 있습니다. kubeadm은 사용자가 변경하기도 수월하고, 온프레미스(On-Premises)와 클라우드를 모두 지원하며, 배우기도 쉽습니다. 

이러한 솔루션들을 `구성형 쿠버네티스`라고 합니다.

![image](https://user-images.githubusercontent.com/62640332/167782538-304d74f9-fea9-4be4-8a61-d12be53091b1.png)

<br>
<br>

```
Tip ☆ 쿠버네티스 구성 요소의 이름 생성 규칙
    
쿠버네티스의 구성 요소는 동시에 여러 개가 존재하는 경우 중복된 이름을 피하려고 뒤에 해시(hash) 코드가 삽입됩니다. 
이때 해시 코드는 무작위 문자열로 생성됩니다.
```

![image](https://user-images.githubusercontent.com/62640332/167785690-9ba5892d-0d5c-4961-8413-d14801b9243b.png)

coredns에는 중간에 5644d7b6d9라는 문자열이 하나 더 있는데, 이는 레플리카셋(ReplicaSet)을 무작위 문자열로 변형해 추가한 것입니다. calico-kube-controllers도 같은 경우입니다.

![image](https://user-images.githubusercontent.com/62640332/167785776-3098f442-68b2-45d6-a03b-566dcbf54bff.png)

<br>
<br>

- 관리자나 개발자가 파드를 배포할 때

![image](https://user-images.githubusercontent.com/62640332/167785874-a6a6f5c6-5737-409a-812f-830675e64add.png)

<br>
<br>

### ㅁ 마스터 노드

- kubectl: 쿠버네티스 클러스터에 명령을 내리는 역할을 합니다. 
 
다른 구성 요소들과 다르게 바로 실행되는 명령 형태인 바이너리(binary)로 배포되기 때문에 마스터 노드에 있을 필요는 없습니다.

하지만 통상적으로 API 서버와 주로 통신하므로 이 책에서는 API 서버가 위치한 마스터 노드에 구성했습니다.

<br>

➊ API 서버: 쿠버네티스 클러스터의 중심 역할을 하는 통로입니다. 

주로 상태 값을 저장하는 etcd와 통신하지만, 그 밖의 요소들 또한 API 서버를 중심에 두고 통신하므로 API 서버의 역할이 매우 중요합니다. 

회사에 비유하면 모든 직원과 상황을 관리하고 목표를 설정하는 관리자에 해당합니다.

<br>
 
➋ etcd: 구성 요소들의 상태 값이 모두 저장되는 곳입니다. 회사의 관리자가 모든 보고 내용을 기록하는 노트라고 생각하면 됩니다. 

실제로 etcd 외의 다른 구성 요소는 상태 값을 관리하지 않습니다. 

그러므로 etcd의 정보만 백업돼 있다면 긴급한 장애 상황에서도 쿠버네티스 클러스터는 복구할 수 있습니다. 

또한 etcd는 분산 저장이 가능한 key-value 저장소이므로, 복제해 여러 곳에 저장해 두면 하나의 etcd에서 장애가 나더라도 시스템의 가용성을 확보할 수 있습니다. 

이와 같은 멀티 마스터 노드 형태는 부록에서 kubespray로 구성해 보겠습니다.

```
Tip ☆ etcd의 의미

etcd(엣시디)를 약어로 오인하는 경우가 있습니다. 
etcd는 리눅스의 구성 정보를 주로 가지고 있는 etc 디렉터리와 distributed(퍼뜨렸다)의 합성어입니다.
따라서 etcd는 구성 정보를 퍼뜨려 저장하겠다는 의미입니다.
```  

<br>

➌ 컨트롤러 매니저: 컨트롤러 매니저는 쿠버네티스 클러스터의 오브젝트 상태를 관리합니다. 

예를 들어 워커 노드에서 통신이 되지 않는 경우, 상태 체크와 복구는 컨트롤러 매니저에 속한 노드 컨트롤러에서 이루어집니다. 

다른 예로 레플리카셋 컨트롤러는 레플리카셋에 요청받은 파드 개수대로 파드를 생성합니다. 

뒤에 나오는 서비스와 파드를 연결하는 역할을 하는 엔드포인트 컨트롤러 또한 컨트롤러 매니저입니다.

이와 같이 다양한 상태 값을 관리하는 주체들이 컨트롤러 매니저에 소속돼 각자의 역할을 수행합니다. 

여기서 나온 오브젝트에 관해서는 ‘3.2.2 오브젝트란’에서 자세히 다룹니다.

<br>

➍ 스케줄러: 노드의 상태와 자원, 레이블, 요구 조건 등을 고려해 파드를 어떤 워커 노드에 생성할 것인지를 결정하고 할당합니다. 

스케줄러라는 이름에 걸맞게 파드를 조건에 맞는 워커 노드에 지정하고, 파드가 워커 노드에 할당되는 일정을 관리하는 역할을 담당합니다.

<br>
<br>

### ㅁ 워커 노드

<br>

➎ kubelet: 파드의 구성 내용(PodSpec)을 받아서 컨테이너 런타임으로 전달하고, 파드 안의 컨테이너들이 정상적으로 작동하는지 모니터링합니다.

<br>

➏ 컨테이너 런타임(CRI, Container Runtime Interface): 파드를 이루는 컨테이너의 실행을 담당합니다. 

파드 안에서 다양한 종류의 컨테이너가 문제 없이 작동하게 만드는 표준 인터페이스입니다. 

자세한 내용은 ‘부록 D 컨테이너 깊게 들여다보기’를 참고하기 바랍니다.

<br>

➐ 파드(Pod): 한 개 이상의 컨테이너로 단일 목적의 일을 하기 위해서 모인 단위입니다. 

즉, 웹 서버 역할을 할 수도 있고 로그나 데이터를 분석할 수도 있습니다. 

여기서 중요한 것은 파드는 언제라도 죽을 수 있는 존재라는 점입니다. 

이것이 쿠버네티스를 처음 배울 때 가장 이해하기 어려운 부분입니다. 

가상 머신은 언제라도 죽을 수 있다고 가정하고 디자인하지 않지만, 파드는 언제라도 죽을 수 있다고 가정하고 설계됐기 때문에 쿠버네티스는 여러 대안을 디자인했습니다. 

어려운 내용이므로 여러 가지 테스트를 통해 여러분이 이해하도록 돕겠습니다.

  
    
 ![image](https://user-images.githubusercontent.com/62640332/167788296-b9fe3509-b218-4e15-8073-bd54ad910703.png)


<br>
<br>

### ㅁ 선택 가능한 구성 요소

0 번부터  7 번까지는 기본 설정으로 배포된 쿠버네티스에서 이루어지는 통신 단계를 구분한 것입니다. 

이외에 선택적으로 배포하는 것들은 순서와 상관이 없기 때문에 10번대로 구분해 표시했습니다. 

선택 가능한 부가 요소들은 이 책에서 다루기에는 너무 깊은 내용이라 이런 요소가 있다는 정도만 알면 충분합니다.

<br>

⓫ 네트워크 플러그인: 쿠버네티스 클러스터의 통신을 위해서 네트워크 플러그인을 선택하고 구성해야 합니다. 

네트워크 플러그인은 일반적으로 CNI로 구성하는데, 주로 사용하는 CNI에는 캘리코(Calico), 플래널(Flannel), 실리움(Cilium), 큐브 라우터(Kube-router), 로마나(Romana), 위브넷(WeaveNet), Canal이 있습니다. 여기서는 캘리코를 선택해 구성했습니다.

<br>

⓬ CoreDNS: 클라우드 네이티브 컴퓨팅 재단에서 보증하는 프로젝트로, 빠르고 유연한 DNS 서버입니다. 

쿠버네티스 클러스터에서 도메인 이름을 이용해 통신하는 데 사용하며, 6장에서 간단히 사용해 볼 예정입니다. 

실무에서 쿠버네티스 클러스터를 구성하여 사용할 때는 IP보다 도메인 네임을 편리하게 관리해 주는 CoreDNS를 사용하는 것이 일반적입니다. 

해당 내용을 자세히 알아보려면 홈페이지(https://coredns.io)를 참조하기 바랍니다.

```  
Tip ☆ CNI

CNI(Container Network Interface, 컨테이너 네트워크 인터페이스)는 클라우드 네이티브 컴퓨팅 재단의 프로젝트로, 컨테이너의 네트워크 안정성과 확장성을 보장하기 위해 개발됐습니다. 
CNI에 사용할 수 있는 네트워크 플러그인은 다양한데, 구성 방식과 지원하는 기능, 성능이 각기 다르므로 사용 목적에 맞게 선택하면 됩니다. 
예를 들어 Calico는 L3로 컨테이너 네트워크를 구성하고, Flannel은 L2로 컨테이너 네트워크를 구성합니다. 
또한 네트워크 프로토콜인 BGP와 VXLAN의 지원, ACL(Access Control List) 지원, 보안 기능 제공 등을 살펴보고 필요한 조건을 가지고 있는 네트워크 플러그인을 선택할 수 있어서 설계 유연성이 매우 높습니다.
```
<br>
<br>

### ㅁ 사용자가 배포된 파드에 접속할 때

1. kube-proxy: 쿠버네티스 클러스터는 파드가 위치한 노드에 kube-proxy를 통해 파드가 통신할 수 있는 네트워크를 설정합니다. 

이때 실제 통신은 br_netfilter와 iptables로 관리합니다. 

두 기능은 Vagrantfile에서 호출하는 config.sh 코드를 설명할 때 다뤘습니다.

<br>

2. 파드: 이미 배포된 파드에 접속하고 필요한 내용을 전달받습니다. 이때 대부분 사용자는 파드가 어느 워커 노드에 위치하는지 신경 쓰지 않아도 됩니다.

쿠버네티스의 각 구성 요소를 파드의 배포와 접속 관점에서 설명했지만, 이해하기는 쉽지 않을 겁니다. 

파드가 배포되는 과정을 살펴보며 쿠버네티스의 구성 요소를 좀 더 깊이 알아보겠습니다.

<br>

쿠버네티스의 가장 큰 장점은 쿠버네티스의 구성 요소마다 하는 일이 명확하게 구분돼 각자의 역할만 충실하게 수행하면 클러스터 시스템이 안정적으로 운영된다는 점입니다. 

이렇게 각자의 역할이 명확하게 나뉘어진 것은 마이크로서비스 아키텍처(MSA) 구조와도 밀접하게 연관됩니다. 

또한 역할이 나뉘어 있어서 문제가 발생했을 때 어느 부분에서 문제가 발생했는지 디버깅하기 쉽습니다.


<br>
<br>

### ㅁ 파드의 생명주기(life cycle)

![image](https://user-images.githubusercontent.com/62640332/167790485-22cbb381-5aa0-4d58-a373-b2bb744c3334.png)

1. kubectl을 통해 API 서버에 파드 생성을 요청합니다.

<br>

2. (업데이트가 있을 때마다 매번) API 서버에 전달된 내용이 있으면 API 서버는 etcd에 전달된 내용을 모두 기록해 클러스터의 상태 값을 최신으로 유지합니다. 
 
따라서 각 요소가 상태를 업데이트할 때마다 모두 API 서버를 통해 etcd에 기록됩니다.

<br>

3. API 서버에 파드 생성이 요청된 것을 컨트롤러 매니저가 인지하면 컨트롤러 매니저는 파드를 생성하고, 이 상태를 API 서버에 전달합니다. 

참고로 아직 어떤 워커 노드에 파드를 적용할지는 결정되지 않은 상태로 파드만 생성됩니다. 이 부분은 ‘3.2.2 오브젝트란’에서 보충 설명하겠습니다.

<br>

4. API 서버에 파드가 생성됐다는 정보를 스케줄러가 인지합니다. 스케줄러는 생성된 파드를 어떤 워커 노드에 적용할지 조건을 고려해 결정하고 해당 워커 노드에 파드를 띄우도록 요청합니다.

5. API 서버에 전달된 정보대로 지정한 워커 노드에 파드가 속해 있는지 스케줄러가 kubelet으로 확인합니다.

6. kubelet에서 컨테이너 런타임으로 파드 생성을 요청합니다.

7. 파드가 생성됩니다.

8. 파드가 사용 가능한 상태가 됩니다.

앞의 내용을 살펴보다가 ‘API 서버는 감시만 하는 걸까? 화살표가 반대로 그려져야 맞지 않을까?’라는 의문이 들었다면 내용을 제대로 본 겁니다.

이 부분은 쿠버네티스를 이해하는 데 매우 중요한 부분입니다. 쿠버네티스는 작업을 순서대로 진행하는 워크플로(workflow, 작업 절차) 구조가 아니라 `선언적인(declarative)` 시스템 구조를 가지고 있습니다. 

즉, 각 요소가 추구하는 상태(desired status)를 선언하면 현재 상태(current status)와 맞는지 점검하고 그것에 맞추려고 노력하는 구조로 돼 있다는 뜻입니다.

따라서 추구하는 상태를 API 서버에 선언하면 다른 요소들이 API 서버에 와서 현재 상태와 비교하고 그에 맞게 상태를 변경하려고 합니다. 

여기서 API는 현재 상태 값을 가지고 있는데, 이것을 보존해야 해서 etcd가 필요합니다. 

API 서버와 etcd는 거의 한몸처럼 움직이도록 설계됐습니다. 다만, 여기서 워커 노드는 워크플로 구조에 따라 설계됐습니다. 

쿠버네티스가 kubelet과 컨테이너 런타임을 통해 파드를 새로 생성하고 제거해야 하는 구조여서 선언적인 방식으로 구조화하기에는 어려움이 있기 때문입니다. 

또한 명령이 절차적으로 전달되는 방식은 시스템의 성능을 높이는 데 효율적입니다. 

하지만 마스터 노드는 이미 생성된 파드들을 유기적으로 연결하므로 쿠버네티스 클러스터를 안정적으로 유지하려면 선언적인 시스템이 더 낫습니다.

<br> 
<br> 

- kubectl

앞에서 kubectl은 꼭 마스터 노드에 위치할 필요 없다고 했습니다. 실제로 쿠버네티스 클러스터의 외부에서 쿠버네티스 클러스터에 명령을 내릴 수도 있습니다.

‘3.1.5 파드 생명주기로 쿠버네티스 구성 요소 살펴보기’를 보면 kubectl은 API 서버를 통해 쿠버네티스에 명령을 내립니다. 

따라서 kubectl이 어디에 있더라도 API 서버의 접속 정보만 있다면 어느 곳에서든 쿠버네티스 클러스터에 명령을 내릴 수 있습니다.

```
# 쿠버네티스 클러스터의 정보(/etc/kubernetes/admin.conf)
```

- kubelet

kubelet은 쿠버네티스에서 파드의 생성과 상태 관리 및 복구 등을 담당하는 매우 중요한 구성 요소입니다. 따라서 kubelet에 문제가 생기면 파드가 정상적으로 관리되지 않습니다.

\# 기능을 검증하려면 실제로 파드를 배포해야 합니다.

- kube-proxy

kubelet이 파드의 상태를 관리한다면 kube-proxy는 파드의 통신을 담당합니다


### ㅁ 쿠버네티스 생성 명령어 run, create 차이점

run으로 파드를 생성하면 단일 파드 1개만 생성되고 관리됩니다. 

create deployment로 파드를 생성하면 디플로이먼트(Deployment)라는 관리 그룹 내에서 파드가 생성됩니다.

![image](https://user-images.githubusercontent.com/62640332/167969742-77ddc81e-e5b4-4abb-8e85-7d160390d239.png)

<br>
<br>

### ㅁ 오브젝트란

쿠버네티스를 사용하는 관점에서 파드와 디플로이먼트는 스펙(spec)과 상태(status) 등의 값을 가지고 있습니다. 

이러한 값을 가지고 있는 파드와 디플로이먼트를 개별 속성을 포함해 부르는 단위를 오브젝트(Object)라고 합니다.

<br>

1. 기본 오브젝트

• 파드(Pod): 쿠버네티스에서 실행되는 최소 단위, 즉 웹 서비스를 구동하는 데 필요한 최소 단위입니다. 

독립적인 공간과 사용 가능한 IP를 가지고 있습니다. 하나의 파드는 1개 이상의 컨테이너를 갖고 있기 때문에 여러 기능을 묶어 하나의 목적으로 사용할 수도 있습니다. 

그러나 범용으로 사용할 때는 대부분 1개의 파드에 1개의 컨테이너를 적용합니다(차이가 조금 있으나 우선 1개라고 이해하겠습니다. 자세한 것은 4장에서 다룹니다).

<br>

• 네임스페이스(Namespaces): 쿠버네티스 클러스터에서 사용되는 리소스들을 구분해 관리하는 그룹입니다. 

예를 들어 3장에서는 3가지 네임스페이스를 사용합니다. 특별히 지정하지 않으면 기본으로 할당되는 default, 

쿠버네티스 시스템에서 사용되는 kube-system, 

온프레미스에서 쿠버네티스를 사용할 경우 외부에서 쿠버네티스 클러스터 내부로 접속하게 도와주는 컨테이너들이 속해 있는 metallb-system이 있습니다.

<br>

• 볼륨(Volume): 파드가 생성될 때 파드에서 사용할 수 있는 디렉터리를 제공합니다. 

기본적으로 파드는 영속되는 개념이 아니라 제공되는 디렉터리도 임시로 사용합니다. 

하지만 파드가 사라지더라도 저장과 보존이 가능한 디렉터리를 볼륨 오브젝트를 통해 생성하고 사용할 수 있습니다.

<br>

• 서비스(Service): 파드는 클러스터 내에서 유동적이기 때문에 접속 정보가 고정일 수 없습니다. 

따라서 파드 접속을 안정적으로 유지하도록 서비스를 통해 내/외부로 연결됩니다. 

그래서 서비스는 새로 파드가 생성될 때 부여되는 새로운 IP를 기존에 제공하던 기능과 연결해 줍니다. 

쉽게 설명하면 쿠버네티스 외부에서 쿠버네티스 내부로 접속할 때 내부가 어떤 구조로 돼 있는지, 파드가 살았는지 죽었는지 신경 쓰지 않아도 이를 논리적으로 연결하는 것이 서비스입니다. 

기존 인프라에서 로드밸런서, 게이트웨이와 비슷한 역할을 합니다. 서비스라는 이름 때문에 처음에 개념을 이해하기가 매우 어렵습니다. 

따라서 ‘3.3 쿠버네티스 연결을 담당하는 서비스’에서 집중적으로 다루겠습니다.

![image](https://user-images.githubusercontent.com/62640332/167970237-b6cd85ec-c8f5-4bf3-aeb5-8966f379a139.png)


<br>
<br>


2. 디플로이먼트

기본 오브젝트만으로도 쿠버네티스를 사용할 수 있습니다. 하지만 한계가 있어서 이를 좀 더 효율적으로 작동하도록 기능들을 조합하고 추가해 구현한 것이 디플로이먼트(Deployment)입니다

쿠버네티스에서 가장 많이 쓰이는 디플로이먼트 오브젝트는 파드에 기반을 두고 있으며, 레플리카셋 오브젝트를 합쳐 놓은 형태입니다

![image](https://user-images.githubusercontent.com/62640332/167970435-f843a24b-57ad-448a-a1ac-40d4edbbd10d.png)

실제로 API 서버와 컨트롤러 매니저는 단순히 파드가 생성되는 것을 감시하는 것이 아니라 디플로이먼트처럼 레플리카셋을 포함하는 오브젝트의 생성을 감시합니다

![image](https://user-images.githubusercontent.com/62640332/167970534-d0591fc1-1277-41d0-a1be-a1c1d16cf041.png)


### ㅁ 디플로이먼트가 필요한 이유

많은 사용자를 대상으로 웹 서비스를 하려면 다수의 파드가 필요한데, 이를 하나씩 생성한다면 매우 비효율적입니다. 

그래서 쿠버네티스에서는 다수의 파드를 만드는 레플리카셋 오브젝트를 제공합니다.

예를 들어 파드를 3개 만들겠다고 레플리카셋에 선언하면 컨트롤러 매니저와 스케줄러가 워커 노드에 파드 3개를 만들도록 선언합니다. 

![image](https://user-images.githubusercontent.com/62640332/167971781-46ca36a1-d036-4e8f-a78a-3a6afad8c445.png)

그러나 레플리카셋은 파드 수를 보장하는 기능만 제공하기 때문에 롤링 업데이트 기능 등이 추가된 디플로이먼트를 사용해 파드 수를 관리하기를 권장합니다

<br>

kubectl create deployment 명령으로 디플로이먼트를 생성하긴 했지만, 1개의 파드만 만들어졌을 뿐입니다. 

디플로이먼트를 생성하면서 한꺼번에 여러 개의 파드를 만들 순 없을까요? create에서는 replicas 옵션을 사용할 수 없고, scale은 이미 만들어진 디플로이먼트에서만 사용할 수 있습니다.

이런 설정을 적용하려면 필요한 내용을 파일로 작성해야 합니다. 

이때 작성하는 파일을 오브젝트 스펙(spec)이라고 합니다. 오브젝트 스펙은 일반적으로 야믈(YAML) 문법으로 작성합니다.

![image](https://user-images.githubusercontent.com/62640332/168002125-fb2b7a76-a1f7-44f2-8cfe-b45460f9b494.png)

run은 파드를 간단하게 생성하는 매우 편리한 방법입니다. 

하지만 run으로는 단일 파드만을 생성할 수 있습니다. 따라서 run을 모든 상황에 적용해 사용하기는 어렵습니다. 

그렇다고 create로 디플로이먼트를 생성하면 앞에서 확인한 것처럼 파일의 변경 사항을 바로 적용할 수 없다는 단점이 있습니다. 

이런 경우를 위해 쿠버네티스는 apply라는 명령어를 제공합니다.

![image](https://user-images.githubusercontent.com/62640332/168003524-a104f41a-e1aa-4b40-96cd-1e17db518e65.png)

<br>
<br>

쿠버네티스는 거의 모든 부분이 자동 복구되도록 설계됐습니다. 

특히 파드의 자동 복구 기술을 `셀프 힐링(Self-Healing)`이라고 하는데, 제대로 작동하지 않는 컨테이너를 다시 시작하거나 교체해 파드가 정상적으로 작동하게 합니다

![image](https://user-images.githubusercontent.com/62640332/168007254-7db95912-d9a9-4944-a5ca-7be6fec4d90b.png)

디플로이먼트에 속한 파드가 삭제되면 레플리카셋이 확인하여 새로운 파드를 생성하여 설정한 replicas의 개수를 유지하지만,

디플로이에 속하지 않은 일반 파드 삭제시 어떤 컨트롤러도 이 파드를 관리 하지 안항서 그냥 삭제되고, 다시 생성X


```
# 디플로이먼트에 속한 파드는 상위 디플로이먼트를 삭제해야 파드가 삭제해야한다.
```

<br>
<br>


노드는 어떤 식으로 관리할까요? 우선 노드의 목적을 명확히 해야 합니다. 

노드는 쿠버네티스 스케줄러에서 파드를 할당받고 처리하는 역할을 합니다.

그런데 최근에 몇 차례 문제가 생긴 노드에 파드를 할당하면 문제가 생길 가능성이 높습니다. 하지만 어쩔 수 없이 해당 노드를 사용해야 한다면 어떻게 할까요? 

이런 경우에는 영향도가 적은 파드를 할당해 일정 기간 사용하면서 모니터링해야 합니다. 즉, 노드에 문제가 생기더라도 파드의 문제를 최소화해야 합니다. 

하지만 쿠버네티스는 모든 노드에 균등하게 파드를 할당하려고 합니다. 그렇다면 어떻게 문제가 생길 가능성이 있는 노드라는 것을 쿠버네티스에 알려줄까요?2

쿠버네티스에서는 이런 경우에 `cordon` 기능을 사용합니다.(해제 명령어는 `uncordon`)

![image](https://user-images.githubusercontent.com/62640332/168013662-f0fb55bc-e821-4608-afea-4f0a03c60ca3.png)

사용시 해당 노드의 상태가  더이상 파드가 할당되지 않는 상태로 변경. 파드수를 늘리든, 줄이든 cordon 설정한 노드는 변경되지 않음.

<br>
<br>

### ㅁ 노드의 커널을 업데이트하거나 노드의 메모리를 증설하는 등의 작업이 필요해서 노드를 꺼야 할 때는 어떻게 하면 좋을까요?

쿠버네티스를 사용하다 보면 정기 또는 비정기적인 유지보수를 위해 노드를 꺼야 하는 상황이 발생합니다. 

이런 경우를 대비해 쿠버네티스는 `drain` 기능을 제공합니다. drain은 지정된 노드의 파드를 전부 다른 곳으로 이동시켜 해당 노드를 유지보수할 수 있게 합니다. 

drain은 실제로 파드를 옮기는 것이 아니라 노드에서 파드를 삭제하고 다른 곳에 다시 생성합니다. 

앞에서도 설명했지만 파드는 언제라도 삭제할 수 있기 때문에 쿠버네티스에서 대부분 이동은 파드를 지우고 다시 만드는 과정을 의미합니다. 

그런데 DaemonSet은 각 노드에 1개만 존재하는 파드라서 drain으로는 삭제할 수 없습니다.

```
# drain 명령과 ignore-daemonsets 옵션을 함께 사용합니다. 이 옵션을 사용하면 DaemonSet을 무시하고 진행
```

![image](https://user-images.githubusercontent.com/62640332/168028896-68a2e571-ffe5-4058-b68a-c926ea542f57.png)


![image](https://user-images.githubusercontent.com/62640332/168030734-afd386df-6951-4b89-abe0-2b304c1dc2a6.png)


<br>
<br>

### ㅁ 쿠버네티스 연결을 담당하는 서비스

일반적으로 서비스라고 하면 웹 서비스나 네트워크 서비스처럼 운영 체제에 속한 서비스 데몬 또는 개발 중인 서비스 등을 떠올릴 겁니다. 

그런데 쿠버네티스에서는 외부에서 쿠버네티스 클러스터에 접속하는 방법을 서비스(service)라고 합니다. 

서비스를 ‘소비를 위한 도움을 제공한다’는 관점으로 바라본다면 쿠버네티스가 외부에서 쿠버네티스 클러스터에 접속하기 위한 ‘서비스’를 제공한다고 볼 수 있습니다.


### ㅁ 노드포트

외부에서 쿠버네티스 클러스터의 내부에 접속하는 가장 쉬운 방법은 노드포트(NodePort) 서비스를 이용하는 것입니다. 

노드포트 서비스를 설정하면 모든 워커 노드의 특정 포트(노드포트)를 열고 여기로 오는 모든 요청을 노드포트 서비스로 전달합니다. 

그리고 노드포트 서비스는 해당 업무를 처리할 수 있는 파드로 요청을 전달합니다.

![image](https://user-images.githubusercontent.com/62640332/168031237-60b0163c-b62a-45a0-a3a5-3976c9bcdd61.png)

